## Current revision codes
Here, we add the codes related to the new experiments related to the "Sentence Ranking Tool" (Section 6). The changes made are as follows : 
1. We added more elaborately explained the  ground truth creation process and task definition of the helper tool. 
2. We have added more evaluation metrics of complementary nature (different research tasks like summarization, classification, information retrieval) of \textit{precision, recall, F1, MAP@1 and MAP@2}. 
3. We also add an error analysis section where we perform an in-depth analysis of the proposed multi-aspect sentence ranking (MASR-3) model, specifically the relationship among the aspects and the semantic properties that are uniquely captured by the models.

### Adding evaluation metrics
We first add the Jupyter notebooks corresponding to the computation of the new evaluation metrics of precision, recall, F1, MAP@1 and MAP@2

### Adding the error analysis codes
